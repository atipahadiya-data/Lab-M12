{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c36011e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ sales_2024_06_01.csv created\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create CSV files simulating daily extracts from a source system.\n",
    "sales_2024_06_01 = pd.DataFrame({\n",
    "    \"order_id\": [\"S001\", \"S002\", \"S003\"],\n",
    "    \"order_date\": [\"2024-06-01\", \"2024-06-01\", \"2024-06-01\"],\n",
    "    \"customer\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "    \"product\": [\"Widget A\", \"Widget B\", \"Widget A\"],\n",
    "    \"amount\": [75.00, 50.00, 150.00]\n",
    "})\n",
    "\n",
    "sales_2024_06_01.to_csv(\"sales_2024_06_01.csv\", index=False)\n",
    "\n",
    "print(\"✅ sales_2024_06_01.csv created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d21e9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ sales_2024_06_02.csv created\n"
     ]
    }
   ],
   "source": [
    "# Create sales_2024_06_02.csv:\n",
    "sales_2024_06_02 = pd.DataFrame({\n",
    "    \"order_id\": [\"S004\" ,\"S005\"],\n",
    "    \"order_date\" : [\"2024-06-02\" , \"2024-06-02\"],\n",
    "    \"customer\" : [\"Diana\" , \"Alice\"],\n",
    "    \"product\": [\"Widget C\", \"Widget B\"],\n",
    "    \"amount\": [30.00, 100.00]  \n",
    "})\n",
    "sales_2024_06_02.to_csv(\"sales_2024_06_02.csv\" , index=False)\n",
    "print(\"✅ sales_2024_06_02.csv created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c4b268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ warehouse.csv created with headers only\n"
     ]
    }
   ],
   "source": [
    "# create an empty csv file with just headers\n",
    "warehouse = pd.DataFrame(\n",
    "    columns=[\"order_id\", \"order_date\", \"customer\", \"product\", \"amount\"]\n",
    ")\n",
    "\n",
    "warehouse.to_csv(\"warehouse.csv\", index=False)\n",
    "\n",
    "print(\"✅ warehouse.csv created with headers only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b86c4a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build an non-idempotent loader ( the problem )\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_non_idempotent(daily_file, warehouse_file):\n",
    "    \"\"\"\n",
    "    NON-IDEMPOTENT loader: blindly appends daily data to warehouse.\n",
    "    Running this twice = DUPLICATE DATA.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"NON-IDEMPOTENT LOAD: {daily_file}\")\n",
    "    print(f\"{'=' * 50}\")\n",
    "    \n",
    "    # Read daily extract\n",
    "    daily_df = pd.read_csv(daily_file)\n",
    "    print(f\"Daily rows to load: {len(daily_df)}\")\n",
    "    \n",
    "    # Read current warehouse\n",
    "    if os.path.exists(warehouse_file) and os.path.getsize(warehouse_file) > 0:\n",
    "        warehouse_df = pd.read_csv(warehouse_file)\n",
    "    else:\n",
    "        warehouse_df = pd.DataFrame(columns=daily_df.columns)\n",
    "    \n",
    "    print(f\"Warehouse rows BEFORE: {len(warehouse_df)}\")\n",
    "    \n",
    "    # BLIND APPEND — the problem!\n",
    "    warehouse_df = pd.concat([warehouse_df, daily_df], ignore_index=True)\n",
    "    \n",
    "    # Save back\n",
    "    warehouse_df.to_csv(warehouse_file, index=False)\n",
    "    print(f\"Warehouse rows AFTER: {len(warehouse_df)}\")\n",
    "    \n",
    "    return warehouse_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8512e7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "NON-IDEMPOTENT LOAD: sales_2024_06_01.csv\n",
      "==================================================\n",
      "Daily rows to load: 3\n",
      "Warehouse rows BEFORE: 0\n",
      "Warehouse rows AFTER: 3\n",
      "\n",
      "Warehouse after first run:\n",
      "  order_id  order_date customer   product amount\n",
      "0     S001  2024-06-01    Alice  Widget A   75.0\n",
      "1     S002  2024-06-01      Bob  Widget B   50.0\n",
      "2     S003  2024-06-01  Charlie  Widget A  150.0\n"
     ]
    }
   ],
   "source": [
    "# run it once for June first\n",
    "\n",
    "# Reset warehouse\n",
    "pd.DataFrame(columns=[\"order_id\",\"order_date\",\"customer\",\"product\",\"amount\"]).to_csv(\"warehouse.csv\", index=False)\n",
    "\n",
    "# First run\n",
    "result = load_non_idempotent(\"sales_2024_06_01.csv\", \"warehouse.csv\")\n",
    "print(f\"\\nWarehouse after first run:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07a78adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "NON-IDEMPOTENT LOAD: sales_2024_06_01.csv\n",
      "==================================================\n",
      "Daily rows to load: 3\n",
      "Warehouse rows BEFORE: 3\n",
      "Warehouse rows AFTER: 6\n",
      "\n",
      "Warehouse after SECOND run (re-run):\n",
      "  order_id  order_date customer   product  amount\n",
      "0     S001  2024-06-01    Alice  Widget A    75.0\n",
      "1     S002  2024-06-01      Bob  Widget B    50.0\n",
      "2     S003  2024-06-01  Charlie  Widget A   150.0\n",
      "3     S001  2024-06-01    Alice  Widget A    75.0\n",
      "4     S002  2024-06-01      Bob  Widget B    50.0\n",
      "5     S003  2024-06-01  Charlie  Widget A   150.0\n",
      "\n",
      "⚠️  PROBLEM: 6 rows — we have DUPLICATES!\n"
     ]
    }
   ],
   "source": [
    "# Run it AGAIN for the same day (simulating a re-run):\n",
    "\n",
    "# Second run — same file, same day\n",
    "result = load_non_idempotent(\"sales_2024_06_01.csv\", \"warehouse.csv\")\n",
    "print(f\"\\nWarehouse after SECOND run (re-run):\")\n",
    "print(result)\n",
    "print(f\"\\n⚠️  PROBLEM: {len(result)} rows — we have DUPLICATES!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83855e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build idempotent loader \n",
    "def load_idempotent(daily_file, warehouse_file):\n",
    "    \"\"\"\n",
    "    IDEMPOTENT loader: delete existing data for the partition, then insert.\n",
    "    Running this 1 time or 100 times produces the SAME result.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"IDEMPOTENT LOAD: {daily_file}\")\n",
    "    print(f\"{'=' * 50}\")\n",
    "    \n",
    "    # Read daily extract\n",
    "    daily_df = pd.read_csv(daily_file)\n",
    "    partition_date = daily_df[\"order_date\"].iloc[0]\n",
    "    print(f\"Daily rows to load: {len(daily_df)}\")\n",
    "    print(f\"Partition date: {partition_date}\")\n",
    "    \n",
    "    # Read current warehouse\n",
    "    if os.path.exists(warehouse_file) and os.path.getsize(warehouse_file) > 0:\n",
    "        warehouse_df = pd.read_csv(warehouse_file)\n",
    "    else:\n",
    "        warehouse_df = pd.DataFrame(columns=daily_df.columns)\n",
    "    \n",
    "    print(f\"Warehouse rows BEFORE: {len(warehouse_df)}\")\n",
    "    \n",
    "    # STEP 1: DELETE existing rows for this partition date\n",
    "    rows_before_delete = len(warehouse_df)\n",
    "    warehouse_df = warehouse_df[warehouse_df[\"order_date\"] != partition_date]\n",
    "    rows_deleted = rows_before_delete - len(warehouse_df)\n",
    "    print(f\"Rows deleted for partition {partition_date}: {rows_deleted}\")\n",
    "    \n",
    "    # STEP 2: INSERT fresh data for this partition\n",
    "    warehouse_df = pd.concat([warehouse_df, daily_df], ignore_index=True)\n",
    "    print(f\"Rows inserted: {len(daily_df)}\")\n",
    "    \n",
    "    # Save back\n",
    "    warehouse_df.to_csv(warehouse_file, index=False)\n",
    "    print(f\"Warehouse rows AFTER: {len(warehouse_df)}\")\n",
    "    \n",
    "    return warehouse_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3c4a5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== RUN 1 =====\n",
      "\n",
      "==================================================\n",
      "IDEMPOTENT LOAD: sales_2024_06_01.csv\n",
      "==================================================\n",
      "Daily rows to load: 3\n",
      "Partition date: 2024-06-01\n",
      "Warehouse rows BEFORE: 0\n",
      "Rows deleted for partition 2024-06-01: 0\n",
      "Rows inserted: 3\n",
      "Warehouse rows AFTER: 3\n"
     ]
    }
   ],
   "source": [
    "# Reset warehouse\n",
    "pd.DataFrame(columns=[\"order_id\",\"order_date\",\"customer\",\"product\",\"amount\"]).to_csv(\"warehouse.csv\", index=False)\n",
    "\n",
    "# First run\n",
    "print(\"===== RUN 1 =====\")\n",
    "result1 = load_idempotent(\"sales_2024_06_01.csv\", \"warehouse.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b95fb0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RUN 2 (re-run) =====\n",
      "\n",
      "==================================================\n",
      "IDEMPOTENT LOAD: sales_2024_06_01.csv\n",
      "==================================================\n",
      "Daily rows to load: 3\n",
      "Partition date: 2024-06-01\n",
      "Warehouse rows BEFORE: 3\n",
      "Rows deleted for partition 2024-06-01: 3\n",
      "Rows inserted: 3\n",
      "Warehouse rows AFTER: 3\n"
     ]
    }
   ],
   "source": [
    "# Second run — same file\n",
    "print(\"\\n===== RUN 2 (re-run) =====\")\n",
    "result2 = load_idempotent(\"sales_2024_06_01.csv\", \"warehouse.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51a63965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RUN 3 (another re-run) =====\n",
      "\n",
      "==================================================\n",
      "IDEMPOTENT LOAD: sales_2024_06_01.csv\n",
      "==================================================\n",
      "Daily rows to load: 3\n",
      "Partition date: 2024-06-01\n",
      "Warehouse rows BEFORE: 3\n",
      "Rows deleted for partition 2024-06-01: 3\n",
      "Rows inserted: 3\n",
      "Warehouse rows AFTER: 3\n"
     ]
    }
   ],
   "source": [
    "# Third run — same file\n",
    "print(\"\\n===== RUN 3 (another re-run) =====\")\n",
    "result3 = load_idempotent(\"sales_2024_06_01.csv\", \"warehouse.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a2b4629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== IDEMPOTENCY VERIFICATION =====\n",
      "Rows after run 1: 3\n",
      "Rows after run 2: 3\n",
      "Rows after run 3: 3\n",
      "All results identical: False\n",
      "❌ NOT IDEMPOTENT: Results differ!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== IDEMPOTENCY VERIFICATION =====\")\n",
    "print(f\"Rows after run 1: {len(result1)}\")\n",
    "print(f\"Rows after run 2: {len(result2)}\")\n",
    "print(f\"Rows after run 3: {len(result3)}\")\n",
    "\n",
    "# Compare DataFrames\n",
    "are_equal = result1.equals(result2) and result2.equals(result3)\n",
    "print(f\"All results identical: {are_equal}\")\n",
    "\n",
    "if are_equal:\n",
    "    print(\"✅ IDEMPOTENT: Safe to re-run!\")\n",
    "else:\n",
    "    print(\"❌ NOT IDEMPOTENT: Results differ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ffd0c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== LOADING JUNE 1 =====\n",
      "\n",
      "==================================================\n",
      "IDEMPOTENT LOAD: sales_2024_06_01.csv\n",
      "==================================================\n",
      "Daily rows to load: 3\n",
      "Partition date: 2024-06-01\n",
      "Warehouse rows BEFORE: 0\n",
      "Rows deleted for partition 2024-06-01: 0\n",
      "Rows inserted: 3\n",
      "Warehouse rows AFTER: 3\n",
      "\n",
      "===== LOADING JUNE 2 =====\n",
      "\n",
      "==================================================\n",
      "IDEMPOTENT LOAD: sales_2024_06_02.csv\n",
      "==================================================\n",
      "Daily rows to load: 2\n",
      "Partition date: 2024-06-02\n",
      "Warehouse rows BEFORE: 3\n",
      "Rows deleted for partition 2024-06-02: 0\n",
      "Rows inserted: 2\n",
      "Warehouse rows AFTER: 5\n",
      "\n",
      "===== FINAL WAREHOUSE =====\n",
      "  order_id  order_date customer   product  amount\n",
      "0     S001  2024-06-01    Alice  Widget A    75.0\n",
      "1     S002  2024-06-01      Bob  Widget B    50.0\n",
      "2     S003  2024-06-01  Charlie  Widget A   150.0\n",
      "3     S004  2024-06-02    Diana  Widget C    30.0\n",
      "4     S005  2024-06-02    Alice  Widget B   100.0\n",
      "\n",
      "Total rows: 5\n",
      "Unique dates: ['2024-06-01', '2024-06-02']\n"
     ]
    }
   ],
   "source": [
    "#load multiple days : load both days data sequentially\n",
    "# Reset warehouse\n",
    "pd.DataFrame(columns=[\"order_id\",\"order_date\",\"customer\",\"product\",\"amount\"]).to_csv(\"warehouse.csv\", index=False)\n",
    "\n",
    "# Load June 1st\n",
    "print(\"===== LOADING JUNE 1 =====\")\n",
    "load_idempotent(\"sales_2024_06_01.csv\", \"warehouse.csv\")\n",
    "\n",
    "# Load June 2nd\n",
    "print(\"\\n===== LOADING JUNE 2 =====\")\n",
    "load_idempotent(\"sales_2024_06_02.csv\", \"warehouse.csv\")\n",
    "\n",
    "# Verify final warehouse\n",
    "print(\"\\n===== FINAL WAREHOUSE =====\")\n",
    "final = pd.read_csv(\"warehouse.csv\")\n",
    "print(final)\n",
    "print(f\"\\nTotal rows: {len(final)}\")\n",
    "print(f\"Unique dates: {sorted(final['order_date'].unique())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b9ba68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RE-RUN JUNE 1 (should not affect June 2) =====\n",
      "\n",
      "==================================================\n",
      "IDEMPOTENT LOAD: sales_2024_06_01.csv\n",
      "==================================================\n",
      "Daily rows to load: 3\n",
      "Partition date: 2024-06-01\n",
      "Warehouse rows BEFORE: 5\n",
      "Rows deleted for partition 2024-06-01: 3\n",
      "Rows inserted: 3\n",
      "Warehouse rows AFTER: 5\n",
      "\n",
      "Total rows: 5\n",
      "June 1 rows: 3\n",
      "June 2 rows: 2\n"
     ]
    }
   ],
   "source": [
    "# Re-run June 1st — June 2nd must be unaffected\n",
    "print(\"\\n===== RE-RUN JUNE 1 (should not affect June 2) =====\")\n",
    "load_idempotent(\"sales_2024_06_01.csv\", \"warehouse.csv\")\n",
    "\n",
    "final = pd.read_csv(\"warehouse.csv\")\n",
    "print(f\"\\nTotal rows: {len(final)}\")\n",
    "print(f\"June 1 rows: {len(final[final['order_date'] == '2024-06-01'])}\")\n",
    "print(f\"June 2 rows: {len(final[final['order_date'] == '2024-06-02'])}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
